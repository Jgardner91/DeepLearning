{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "laughing-spanking",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time, os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pandas as pd\n",
    "import shutil as sh\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "defined-sacramento",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_list = [['siberian'],['brittish','shorthair'],['persian'],\n",
    "              ['main','coon'],['ragdoll'],['american','shorthair'],['abyssinian'],['scottish','fold'],\n",
    "             ['norwegian','forest'],['burmese'],['birman'],['russian','blue'],['japanese','bobtail'],\n",
    "             ['munchkin'],['bombay'],['manx'],['oriental','shorthair'],['cornish','rex'],['turkish','angora'],\n",
    "             ['american','bobtail'],['himalayan'],['chartreux'],['tonkinese'],['turkish','van'],['LaPerm'],\n",
    "             ['snowshoe'],['peterbald'],['havana','brown'],['brumilla'],['lykoi'],['cymric'],['donskoy'],['chausie'],\n",
    "             ['ragamuffin'],['selkirk','rex'],['american','wirehair']]\n",
    "len(query_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "future-satellite",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_breeds(query_list,get_specific_breed,stop_scrape):\n",
    "    \n",
    "    '''\n",
    "    * * * * * * * *\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    query_list: List of different breed types\n",
    "    get_specific_breed: Index of specific breed in query list \n",
    "    stop_scrape: Index of specific breed in query list youd like to stop at\n",
    "    \n",
    "    Output\n",
    "    ------ \n",
    "    \n",
    "    Scrape first 40 pages of a specific breed search on Istock \n",
    "    \n",
    "    Set stop_scrape = (get_specific_breed + 1) for breed at specif index in query_list\n",
    "    \n",
    "    Set stop_scrape = integer < 36, for breed at specific index in query list and all breeds up to integer \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    count = 0\n",
    "    for j in range(get_specific_breed,stop_scrape):\n",
    "  \n",
    "        for i in range(2,40):\n",
    "            chromedriver = \"/Applications/chromedriver\" \n",
    "            os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "            # google images search query --- > 'cat type + cat(noun)'\n",
    "            if len(query_list[j]) == 2:\n",
    "                url5 = 'https://www.istockphoto.com/search/2/image?numberofpeople=none&page={}&phrase={}%20{}%20cat&sort=best'.format(i,query_list[j][0],query_list[j][1])\n",
    "            \n",
    "            if len(query_list[j]) == 1:\n",
    "            \n",
    "                url5 = 'https://www.istockphoto.com/search/2/image?numberofpeople=none&page={}&phrase={}%20cat&sort=best'.format(i,query_list[j][0])\n",
    "            \n",
    "            response = requests.get(url5)\n",
    "            page = response.text\n",
    "            soup6 = BeautifulSoup(page, \"lxml\")\n",
    "            driver = webdriver.Chrome(chromedriver)\n",
    "            driver.get(url5)\n",
    "            driver.page_source[:]\n",
    "            time.sleep(3)\n",
    "            soup6 = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            images = soup6.find_all('img')\n",
    "            for k in range(6,(len(images)-7)):\n",
    "                link = images[k].attrs['src']\n",
    "                full_url = link\n",
    "                r = requests.get(full_url, stream=True) #Get request on full_ur\n",
    "                if r.status_code == 200:\n",
    "                # writing image to file \n",
    "                #make sure file already on machine \n",
    "                    with open(\"{}best/{}{}.jpg\".format(query_list[j][0],query_list[j][0],count), 'wb') as f: \n",
    "                        r.raw.decode_content = True\n",
    "                        sh.copyfileobj(r.raw, f)\n",
    "                        count += 1 \n",
    "            driver.close() \n",
    "   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "announced-bleeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_breeds(query_list,2,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "trained-hundred",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function get_breeds in module __main__:\n",
      "\n",
      "get_breeds(query_list, get_specific_breed, stop_scrape)\n",
      "    * * * * * * * *\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    \n",
      "    query_list: List of different breed types\n",
      "    get_specific_breed: Index of specific breed in query list \n",
      "    stop_scrape: Index of specific breed in query list youd like to stop at\n",
      "    \n",
      "    Output\n",
      "    ------ \n",
      "    \n",
      "    Scrape first 40 pages of a specific breed search on Istock \n",
      "    \n",
      "    Set stop_scrape = (get_specific_breed + 1) for breed at specif index in query_list\n",
      "    \n",
      "    Set stop_scrape = integer < 36, for breed at specific index in query list and all breeds up to integer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(get_breeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "square-provincial",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_script(breed):\n",
    "    '''\n",
    "    This is a test script for seaching for images without people\n",
    "    Pass a breed and see the first page of results \n",
    "    \n",
    "    Example: test_script('siberian') \n",
    "    '''\n",
    "    \n",
    "    chromedriver = \"/Applications/chromedriver\" \n",
    "    os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "    # google images search query --- > 'cat type + cat(noun)' \n",
    "    url5 = 'https://www.istockphoto.com/search/2/image?numberofpeople=none&phrase={}%20cat'.format(breed)\n",
    "    response = requests.get(url5)\n",
    "    page = response.text\n",
    "    soup5 = BeautifulSoup(page, \"lxml\")\n",
    "    driver = webdriver.Chrome(chromedriver)\n",
    "    driver.get(url5)\n",
    "    driver.page_source[:]\n",
    "    time.sleep(3)\n",
    "    soup5 = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    driver.close()\n",
    "    return soup5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-trauma",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
